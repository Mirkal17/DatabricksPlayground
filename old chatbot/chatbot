import streamlit as st
import os 
import requests
import json

from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# Get the API key
api_key = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=api_key) if api_key else None

DATABRICKS_HOST = os.getenv("DATABRICKS_HOST")
DATABRICKS_TOKEN = os.getenv("DATABRICKS_TOKEN")  
DATABRICKS_CLUSTER_ID = os.getenv("DATABRICKS_CLUSTER_ID")  


st.title("Data Cleaning Chatbot")

#User Inputs
table_name = st.text_input("Enter the Databricks table name (e.g., `default.epl_data`)")
column_name = st.text_input("Enter name of the column with missing values")
cleaning_action = st.text_input("How would you like to clean your data?")

if column_name and cleaning_action:
    prompt = f""" The dataset contains missing values in the column: {column_name}.
    The user wants to perform the following action: {cleaning_action}.
    Generate PySpark code to clean the missing values as requested. """

    response = client.chat.completions.create(
        messages = [{ "role": "system", "content": "Your a data scientist with an expertise in data cleaning using PySpark"},
                 {"role": "user", "content": prompt}],
        model = "gpt-4o"
        
    )

    generated_code = response.choices[0].message.content

    st.subheader("Generated PySpark Code:")
    st.code(generated_code, language = 'python')

    def run_generated_in_databricks(code):

        url = f"{DATABRICKS_HOST}/api/2.1/jobs/runs/submit"

        headers = {
            "Authorization": f"Bearer {DATABRICKS_TOKEN}",
            "Content-Type": "application/json"
        }

        payload = {
            "run_name": "Streamlit Data Cleaning Job",
            "existing_cluster_id": DATABRICKS_CLUSTER_ID,
            "notebook_task": {
                "notebook_path": "/Users/t833547@spark.co.nz/ML-Playground/pyspark_run",
                "base_parameters": {
                    "code": code,
                    "table_name": table_name
                }
            }
        }

        try:
            response = requests.post(url, headers=headers, json=payload)
            response.raise_for_status()  # Raises HTTPError for 4xx/5xx
            return response.json()

        except requests.exceptions.RequestException as e:
            st.error(f"API Request Failed: {str(e)}")
            return None



    
    if st.button("Run on Databricks"):
        if not all([DATABRICKS_HOST, DATABRICKS_TOKEN, DATABRICKS_CLUSTER_ID]):
            st.error("Missing Databricks configurations. Check environment variables.")
        else:
            st.info("Sending job to Databricks...")
            result = run_generated_in_databricks(generated_code)
            
            if result and 'run_id' in result:
                st.success(f"Job submitted successfully! Run ID: {result['run_id']}")
                job_url = f"{DATABRICKS_HOST}/#job/{result['run_id']}"
                st.markdown(f"Track execution: [Job Dashboard]({job_url})")
            else:
                st.error("Job submission failed. Check the following details:")
                st.json(result)  # Show raw API response



